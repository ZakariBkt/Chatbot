{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Personalized Virtual Assistant: Build an app that integrates with OpenAI APIs to create a highly customizable virtual assistant. Users can interact with the assistant through voice or text, and the app leverages OpenAI's language model API to generate intelligent responses and perform tasks such as scheduling meetings, answering questions, and even making recommendations based on user preferences.\n",
      "\n",
      "2. Creative Writing Prompts: Develop an app that provides users with creative writing prompts generated by OpenAI's language model. Users can specify the genre, mood, or specific elements they want the prompts to include, and the app generates unique and inspiring writing ideas. It can help aspiring writers overcome writer's block and fuel their creativity.\n",
      "\n",
      "3. Personalized Learning Platform: Create an app that leverages OpenAI's language model API to build a personalized learning platform. Users can input their learning goals and preferences, and the app generates custom learning materials, such as articles, quizzes, and tutorials. The app can adapt to the user's progress and provide tailored recommendations for further learning, making education more engaging and effective.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = open(\"OPENAI_API_KEY.txt\", \"r\").read().strip(\"\\n\")\n",
    "\n",
    "completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": \"Give me 3 ideas for apps I could build with openai apis \"}])\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = open(\"OPENAI_API_KEY.txt\", \"r\").read().strip(\"\\n\")\n",
    "\n",
    "messages = []\n",
    "system_msg = input(\"What type of chatbot would you like to create?\\n\")\n",
    "messages.append({\"role\": \"system\", \"content\": system_msg})\n",
    "\n",
    "print(\"Your new assistant is ready!\")\n",
    "while input != \"quit()\":\n",
    "    message = input()\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages)\n",
    "    reply = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    print(\"\\n\" + reply + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "Running on public URL: https://2ab38daf0416ddd774.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2ab38daf0416ddd774.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import gradio\n",
    "\n",
    "openai.api_key = open(\"OPENAI_API_KEY.txt\", \"r\").read().strip(\"\\n\")\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are Batman\"}]\n",
    "\n",
    "def CustomChatGPT(user_input, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are Batman. Answer like you are him. Use any information you have o make a link witha situation with Batman\"}]\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = messages \n",
    "    )\n",
    "    ChatGPT_reply = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    messages.append({\"role\": \"assistant\", \"content\": ChatGPT_reply})\n",
    "    return ChatGPT_reply\n",
    "\n",
    "demo = gradio.ChatInterface(CustomChatGPT)\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "\n",
    "openai.api_key = open(\"OPENAI_API_KEY.txt\", \"r\").read().strip(\"\\n\") # Replace with your key\n",
    "\n",
    "llm = ChatOpenAI(temperature=1.0, model='gpt-3.5-turbo-0613',openai_api_key= open(\"OPENAI_API_KEY.txt\", \"r\").read().strip(\"\\n\"))\n",
    "\n",
    "def predict(message, history):\n",
    "    history_langchain_format = []\n",
    "    for human, ai in history:\n",
    "        history_langchain_format.append(HumanMessage(content=human))\n",
    "        history_langchain_format.append(AIMessage(content=ai))\n",
    "    history_langchain_format.append(HumanMessage(content=message))\n",
    "    gpt_response = llm(history_langchain_format)\n",
    "    return gpt_response.content\n",
    "\n",
    "gr.ChatInterface(predict).launch() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
